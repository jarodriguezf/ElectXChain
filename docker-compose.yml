version: "3.8"

services:
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    environment:
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MANAGER_KEY_OTP: ${MANAGER_KEY}
      DECRYPT_KEY: ${DECRYPT_KEY}
      TZ: Europe/Madrid
    ports:
      - "80:80"
    volumes:
      - ./api/run.py:/back-api/run.py
      - ./api/app:/back-api/app
      - ./system_public_key.pem:/back-api/system_public_key.pem
      - ./kafka/producer_1.py:/back-api/kafka/producer_1.py
      - ./kafka/config.py:/back-api/kafka/config.py
    depends_on:
      db:
        condition: service_healthy
    networks:
      ElectXChain_network:
        aliases:
          - "api_host"

  db:
    image: mariadb:latest
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: db_electionxchain
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - data_db:/var/lib/mysql
      - ./custom.cnf:/etc/mysql/conf.d/custom.cnf
    healthcheck:
      test: ["CMD", "healthcheck.sh", "--connect", "--innodb_initialized"]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 3
    ports:
      - "3306:3306"
    networks:
      ElectXChain_network:
        aliases:
          - "db_host"

  kafka:
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_LISTENER_NAME: INSIDE
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_RETENTION_MINUTES: 300
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1048576
      # logs
      KAFKA_LOG_RETENTION_MS: 900000
      KAFKA_LOG_RETENTION_BYTES: 1048576
      KAFKA_LOG_SEGMENT_BYTES: 1048576
    volumes:
      - /dev/null:/kafka/logs
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      ElectXChain_network:
        aliases:
          - "kafka_host"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "1"

  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      ElectXChain_network:
        aliases:
          - "zook_host"

  spark:
    image: bitnami/spark:3.2.0
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
    depends_on:
      - kafka
    networks:
      ElectXChain_network:
        aliases:
          - "spark_host"

  spark_script:
    build:
      context: ./spark
      dockerfile: Dockerfile
    environment:
      SPARK_MASTER: spark:/spark:7077
      REDIS_HOST: redis_host
      REDIS_PORT: 6379
    depends_on:
      - spark
      - redis
    volumes:
      - ./spark/spark_process.py:/app/spark_process.py
      - ./spark/send_redis_data.py:/app/send_redis_data.py
    networks:
      ElectXChain_network:
        aliases:
          - "spark_process_host"

  redis:
    image: redis:latest
    container_name: redis-cache
    ports:
      - "6379:6379"
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    networks:
      ElectXChain_network:
        aliases:
          - "redis_host"

  # GUI REDIS 
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    ports:
      - "8081:8081"
    environment:
      - REDIS_HOSTS=local:redis:6379
    depends_on:
      - redis
    networks:
      ElectXChain_network:
        aliases:
          - "redis_commander"

  hardhat:
    build: 
      context: ./blockchain
      dockerfile: Dockerfile-hardhat
    ports:
      - "8545:8545"
    volumes:
      - ./blockchain:/app
    stdin_open: true
    tty: true
    entrypoint: ["sh", "-c", "npx hardhat node"]
    networks:
      ElectXChain_network:
        aliases:
          - "hardhatnode_host"

  hardhat-deployer:
    build: 
      context: ./blockchain
      dockerfile: Dockerfile-hardhat
    depends_on:
      - hardhat
    volumes:
      - ./blockchain:/app
    entrypoint: ["sh", "-c", "npx hardhat compile && npx hardhat run scripts/deploy.js --network hardhatnode_host"]
    networks:
      ElectXChain_network:
        aliases:
          - "hardhat-deployer_host"

  hardhat-monitor:
    build:
      context: ./blockchain
      dockerfile: Dockerfile-monitor
    environment:
      - REDIS_HOST=redis_host
      - REDIS_PORT=6379
    depends_on:
      - redis
      - hardhat
    volumes:
      - ./blockchain:/app
      - ./kafka/producer_2.js:/app/scripts/producer_2.js
    command: sh -c "sleep 60 && npx hardhat run scripts/extract_and_store.js --network hardhatnode_host"
    networks:
      ElectXChain_network:
        aliases:
          - "hardhat-monitor_host"
  
  spark_counter:
    build:
      context: ./spark
      dockerfile: Dockerfile-counter
    environment:
      DECRYPT_KEY: ${DECRYPT_KEY}
      SPARK_MASTER: spark:/spark:7077
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    depends_on:
      - db
      - spark
    volumes:
      - ./spark/spark_counter.py:/app/spark_counter.py
      - ./system_private_key.pem:/app/system_private_key.pem
      - ./spark/decrypt_validate:/app/decrypt_validate
      - ./spark/db_connection:/app/db_connection
    networks:
      ElectXChain_network:
        aliases:
          - "spark_countervote_host"

networks: 
  ElectXChain_network:
    name: Elect_net 
    driver: bridge 
    ipam: 
      driver: default

volumes:
  data_db:

